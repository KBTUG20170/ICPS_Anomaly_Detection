{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **Producer**"
      ],
      "metadata": {
        "id": "lcgyy97BeOZM"
      },
      "id": "lcgyy97BeOZM"
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "import socket\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "vDLEYyfadfpX"
      },
      "id": "vDLEYyfadfpX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The server details (where the topic resides)"
      ],
      "metadata": {
        "id": "zRtRyIIedom0"
      },
      "id": "zRtRyIIedom0"
    },
    {
      "cell_type": "code",
      "source": [
        "conf = {'bootstrap.servers': \"localhost:9092\",\n",
        "        'client.id': socket.gethostname()}"
      ],
      "metadata": {
        "id": "Pw_wo8vgdify"
      },
      "id": "Pw_wo8vgdify",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "producer = Producer(conf)"
      ],
      "metadata": {
        "id": "7-Algd2adkDN"
      },
      "id": "7-Algd2adkDN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Take each data point from the dummy dataset, push it to the topic as json, every 10 seconds"
      ],
      "metadata": {
        "id": "Z3vyCvU7dw7z"
      },
      "id": "Z3vyCvU7dw7z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342cebc8-1687-4f25-b8ea-210acfc873ed",
      "metadata": {
        "id": "342cebc8-1687-4f25-b8ea-210acfc873ed"
      },
      "outputs": [],
      "source": [
        "for i, df in enumerate(pd.read_csv('dummy.csv', chunksize=1)):\n",
        "    json = df.loc[i].to_json()\n",
        "    producer.produce(\"electra\",json)\n",
        "    time.sleep(10)\n",
        "producer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Consumer**"
      ],
      "metadata": {
        "id": "eXTN3mGveUBN"
      },
      "id": "eXTN3mGveUBN"
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Consumer\n",
        "import socket\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType\n",
        "from pyspark.ml import PipelineModel"
      ],
      "metadata": {
        "id": "CJK1t7Y1fjNN"
      },
      "id": "CJK1t7Y1fjNN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The server details (where the topic resides), Grp ID is used to identify the consumers of a particular group"
      ],
      "metadata": {
        "id": "MGW-T-dlfpqq"
      },
      "id": "MGW-T-dlfpqq"
    },
    {
      "cell_type": "code",
      "source": [
        "conf = {'bootstrap.servers': \"localhost:9092\",\n",
        "        'group.id': \"foo\",'auto.offset.reset':'earliest'}"
      ],
      "metadata": {
        "id": "m53uXTjZfmzv"
      },
      "id": "m53uXTjZfmzv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating a Spark session"
      ],
      "metadata": {
        "id": "97HKdmtugGzg"
      },
      "id": "97HKdmtugGzg"
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local\").appName(\"electra-pred\").getOrCreate()"
      ],
      "metadata": {
        "id": "sH73nZtLgEbO"
      },
      "id": "sH73nZtLgEbO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Defining a schema, to format the incoming JSON to Spark Dataframe, for prediction"
      ],
      "metadata": {
        "id": "E27MnP-JgMWI"
      },
      "id": "E27MnP-JgMWI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da543911-4a90-4bef-a8a0-8d3604d843d4",
      "metadata": {
        "id": "da543911-4a90-4bef-a8a0-8d3604d843d4"
      },
      "outputs": [],
      "source": [
        "electraSchema = StructType() \\\n",
        "                        .add(\"Time\", \"long\")\\\n",
        "                        .add(\"smac\", \"string\")\\\n",
        "                        .add(\"dmac\", \"string\")\\\n",
        "                        .add(\"sip\", \"string\")\\\n",
        "                        .add(\"dip\", \"string\")\\\n",
        "                        .add(\"request\", \"integer\")\\\n",
        "                        .add(\"fc\", \"integer\")\\\n",
        "                        .add(\"error\", \"integer\")\\\n",
        "                        .add(\"address\", \"integer\")\\\n",
        "                        .add(\"data\", \"integer\")\\\n",
        "                        .add(\"label\", \"string\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Loading the trained model"
      ],
      "metadata": {
        "id": "n__2eBJNglpw"
      },
      "id": "n__2eBJNglpw"
    },
    {
      "cell_type": "code",
      "source": [
        "model = PipelineModel.load('./electra-model')"
      ],
      "metadata": {
        "id": "h6DbO9TOgj4Q"
      },
      "id": "h6DbO9TOgj4Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating a consumer instance and subscribing to the Kafka topic"
      ],
      "metadata": {
        "id": "T2MWtVXlgsUS"
      },
      "id": "T2MWtVXlgsUS"
    },
    {
      "cell_type": "code",
      "source": [
        "consumer = Consumer(conf)\n",
        "consumer.subscribe(['electra'])"
      ],
      "metadata": {
        "id": "N6xf6WLxgrLY"
      },
      "id": "N6xf6WLxgrLY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    while True:\n",
        "        msg = consumer.poll(1.0) #timeout for listening to the topic\n",
        "        if msg is None:\n",
        "            continue\n",
        "        if msg.error():\n",
        "            print('Error: {}'.format(msg.error()))\n",
        "            continue\n",
        "\n",
        "        # Load JSON (values from key-value pairs) data from the topic\n",
        "        data = msg.value().decode('utf-8')\n",
        "        val = list(json.loads(data).values())\n",
        "\n",
        "        # Loading it into a dataframe\n",
        "        df = spark.createDataFrame(data=[(val)], schema=electraSchema)\n",
        "\n",
        "        # Formatting the data as a CSV chunk\n",
        "        val = \",\".join([str(x) for x in val[0:len(val)-1]])\n",
        "\n",
        "        # Obtaining a label prediction for the current data point\n",
        "        pred = model.transform(df)\n",
        "        prediction = int(pred.collect()[0][22])\n",
        "        labels = list(model.stages[0].labelsArray[4])\n",
        "\n",
        "        # Appending the prediction to the CSV chunk\n",
        "        val += \",\"+labels[prediction]\n",
        "        print(val)\n",
        "\n",
        "        # Remove first 2 lines of d.csv, using a temp file\n",
        "        os.system(\"sed '2d' d.csv > temp.csv\")\n",
        "        os.system(\"mv -f temp.csv d.csv\")\n",
        "\n",
        "        # Append the latest data point to d.csv as well as the aggregator CSV in the hdfs\n",
        "        os.system('echo \"{}\" >> ./d.csv'.format(val))\n",
        "        os.system('echo \"{}\" | hdfs dfs -appendToFile - /electra/electra_modbus.csv'.format(val))\n",
        "    consumer.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "PWVIvVZWgiEV"
      },
      "id": "PWVIvVZWgiEV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}